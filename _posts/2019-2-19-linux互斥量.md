---
layout: post
title: "linux互斥量"
date: 2019-2-5
excerpt: "linux内核"
tags: [操作系统,linux内核]
comments: true
---

# 回顾历史

### 自旋锁 

- ```c
  typedef struct arch_spinlock {
          union {
                  __ticketpair_t head_tail;
                  struct __raw_tickets {
                          __ticket_t head, tail;
                  } tickets;
          };
  } arch_spinlock_t;
  ```

  两种类型（队列自旋锁、标签自旋锁），适用于实时进程。 不会将等待进程睡眠

### 信号量

- ```c
  struct semaphore {
  	raw_spinlock_t		lock;
  	unsigned int		count;
  	struct list_head	wait_list;
  };
  ```

  相比自旋锁，信号量加入了等待队列并会调度等待该信号量上的进程

# 动机

多个进程可以同时拥有信号量（普通信号量），他们可以访问共享资源。是不是需要一种更为严格的锁来保证此锁只会有一个进程拥有（二值信号量也可以吧）

# 基本结构

```c
struct mutex {
        atomic_t                count;
        spinlock_t              wait_lock;
        struct list_head        wait_list;
#if defined(CONFIG_DEBUG_MUTEXES) || defined(CONFIG_MUTEX_SPIN_ON_OWNER)
        struct task_struct      *owner;
#endif
#ifdef CONFIG_MUTEX_SPIN_ON_OWNER
        struct optimistic_spin_queue osq;
#endif
#ifdef CONFIG_DEBUG_MUTEXES
        void                    *magic;
#endif
#ifdef CONFIG_DEBUG_LOCK_ALLOC
        struct lockdep_map      dep_map;
#endif
};
```

mutex的结构和semphore结构类似。count代表lock的状态，当count == 1 代表mutex是属于unlock状态。当count的值是0，mutex属于lock状态。

wait_lock是为保护等待队列的自旋锁，wait_list代表一个锁上的等待队列。

magic和dep_map用于内核调试

现在我们知道了mutex的结构，我们可能思考mutex在内核中的并发性。或许一个进程想要获取一个锁必须减少mutex->count中的值。如果一个进程想要释放一个锁，它必须减少mutex->count中相同的值。**linux内核中并非如此简单**

实际上，当一个进程获取一个mutex，有三种可能的路径

- fastpath
- midpath
- slowpath

哪个被执行，取决于当时mutex的状态。fastpath顾名思义是最快的，在fastpath上所有事都很简单。没有进程获取此mutex，当进程获取锁时只要增加mutex->count中的值，当然增加操作必须是原子操作。

当一个进程获取一个mutex但是它已经被其他进程所获取，这是将转到midpath(乐观自旋锁)。本条路径只有此时没有其他进程高优先级的进程处于ready状态。本条路径称为乐观锁因为等待的调度实体不会被投入睡眠和调度，这避免了昂贵的上下文切换。

当fastpath和midpath没有被执行，slowpath将要被执行。本条路径类似于信号量。当没有获得锁，本进程将加入等待队列。

```c
struct mutex_waiter {
        struct list_head        list;
        struct task_struct      *task;
#ifdef CONFIG_DEBUG_MUTEXES
        void                    *magic;
#endif
};
```

这个结构貌似和信号量的结构差不多，唯一的区别是mutex没有up成员但是包括可magic成员。（取决于内核调试）

# Mutex API

在如何对mutex加锁与减锁之前先了解一哈初始mutex的初始化

### init

- **静态初始化**

  ```c
  #define DEFINE_MUTEX(mutexname) \
          struct mutex mutexname = __MUTEX_INITIALIZER(mutexname)
  ```

  ```
  #define __MUTEX_INITIALIZER(lockname)         \
  {                                                             \
         .count = ATOMIC_INIT(1),                               \
         .wait_lock = __SPIN_LOCK_UNLOCKED(lockname.wait_lock), \
         .wait_list = LIST_HEAD_INIT(lockname.wait_list)        \
  }
  ```

- **动态初始化**

  ```c
  # define mutex_init(mutex) \
  do {							\
  	static struct lock_class_key __key;		\
  							\
  	__mutex_init((mutex), #mutex, &__key);		\
  } while (0)
  ```

  ```c
  void
  __mutex_init(struct mutex *lock, const char *name, struct lock_class_key *key)
  {
          atomic_set(&lock->count, 1);
          spin_lock_init(&lock->wait_lock);
          INIT_LIST_HEAD(&lock->wait_list);
          mutex_clear_owner(lock);
  #ifdef CONFIG_MUTEX_SPIN_ON_OWNER
          osq_lock_init(&lock->osq);
  #endif
          debug_mutex_init(lock, name, key);
  }
  ```

  __mutex_init拥有三个参数

  lock - mutex

  name - 调试

  key    -   死锁检测

  init函数将mutex设置为解锁状态通过原子操作函数atomic_set。之后初始化自旋锁和队列。之后清除自旋锁的拥有者并通过osq_lock_init初始化乐观锁队列（解锁状态）

  ```c
  static inline bool osq_is_locked(struct optimistic_spin_queue *lock)
  {
          return atomic_read(&lock->tail) != OSQ_UNLOCKED_VAL;
  }
  ```

### lock

```c
void __sched mutex_lock(struct mutex *lock)
{
        might_sleep();
        __mutex_fastpath_lock(&lock->count, __mutex_lock_slowpath);
        mutex_set_owner(lock);
}
```

- might_sleep()在debug模式下生效

- __mutex_fastpath_lock与架构有关内部是一系列汇编函数(待续...),本函数尝试获取锁通过fast path或用其他方式尝试将mutex--

- 如果fast path 成功将调用mutex_set_owner 

- 如果尝试加锁失败__mutex_lock_slowpath将要被调用

